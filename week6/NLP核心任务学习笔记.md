# NLP 核心任务学习笔记

## 一、机器翻译任务（Machine Translation, MT）

### 1. 核心框架（Seq2Seq 与 Attention）



*   **Seq2Seq 模型**：Seq2Seq 模型作为机器翻译早期的重要框架，由编码器（Encoder）和解码器（Decoder）构成。编码器的作用是将源语言序列（例如中文句子 “我喜欢苹果”）逐步处理，最终压缩成一个固定长度的语义向量，这个向量试图囊括整个源语言句子的关键信息。而解码器则以编码器输出的语义向量作为初始输入，按照顺序逐个生成目标语言序列中的单词（如英文句子 “I like apples”）。这种结构解决了翻译任务中输入序列和输出序列长度不一致的难题，具有开创性意义。例如，在简单的英汉翻译场景中，编码器可以将中文句子的词向量依次输入循环神经网络（RNN）或者长短期记忆网络（LSTM），通过隐藏层状态的传递和更新，最终得到一个能代表整句语义的向量。解码器则以该向量作为初始隐藏状态，不断预测并生成英文单词。

*   **Attention 机制**：在 Seq2Seq 模型基础上发展而来的 Attention 机制，是对传统 Seq2Seq 的重大改进。在早期的 Seq2Seq 中，存在长序列信息丢失的问题，即当源语言句子较长时，编码器压缩得到的固定长度语义向量难以完整保留所有信息，导致解码器在生成目标语言时出现信息遗漏或不准确。Attention 机制通过引入一种动态加权的方式，让解码器在生成每一个目标语言单词时，能够动态地关注源语言序列中不同位置的信息。例如，在翻译 “他在图书馆认真地阅读一本有趣的书” 这句话时，当解码器生成 “book” 这个单词时，Attention 机制会使得模型更关注源语言句子中 “书” 这个词及其周边相关词汇的信息，而不是仅仅依赖于编码器输出的固定向量，从而提升翻译的准确性。

### 2. 机器翻译的核心内容



*   **主流模型**：

  **Transformer**：2017 年提出的 Transformer 模型，彻底改变了机器翻译乃至整个自然语言处理领域的格局。它完全摒弃了传统的 RNN 结构，转而采用自注意力机制（Self - Attention）。自注意力机制允许模型在处理每个位置的单词时，同时考虑句子中其他所有位置单词的信息，从而大大增强了模型对长距离依赖关系的捕捉能力，并且使得模型能够并行计算，极大地提高了训练和推理速度。目前，Google 翻译、DeepL 等工业界领先的翻译系统都以 Transformer 为核心架构，并在其基础上进行了大量优化和扩展，例如采用多语言预训练、引入更多的语言对数据进行联合训练等，以提升翻译质量和支持更多语言的翻译。

**多语言翻译**：随着全球化的发展，多语言翻译需求日益增长。当前的多语言翻译模型，如 mBART 等，具备强大的能力。它们能够在多种语言之间直接进行翻译，实现 “一对多”（如从中文翻译成英文、法文、德文等多种语言）、“多对一”（如将英文、日文、韩文等多种语言翻译成中文）甚至 “多对多”（如在 100 多种语言之间相互切换翻译）的复杂翻译任务。这种多语言翻译能力不仅依赖于大规模多语言语料库的训练，还需要模型在架构设计上能够有效共享不同语言之间的语义和语法信息，例如通过共享编码器和解码器的部分参数，使得模型在学习多种语言时能够相互促进，提升整体翻译性能。

*   **歧义处理**：自然语言中普遍存在一词多义的现象，这给机器翻译带来了极大挑战。以英文单词 “bank” 为例，它在不同语境下既可以表示 “银行”，也可以表示 “河岸”。在翻译过程中，模型需要结合上下文信息准确判断其含义。例如，句子 “He went to the bank to deposit money.”，通过 “deposit money（存钱）” 这个上下文线索，模型应能判断出 “bank” 在此处指 “银行”；而在句子 “The house is near the bank of the river.” 中，“of the river（河流的）” 表明 “bank” 指 “河岸”。为了解决歧义问题，当前的翻译模型通常会利用更丰富的上下文特征，如基于大规模语料库训练的词向量、句子的句法结构信息等，来辅助判断单词的准确含义。

*   **文化差异**：不同语言背后蕴含着丰富的文化差异，这在翻译谚语、俚语等具有文化特定内涵的表达时尤为明显。例如，中文里的 “龙” 在传统文化中象征着吉祥、权威和尊贵，但在西方文化中，“dragon” 往往被视为邪恶、凶猛的象征。因此，在翻译涉及 “龙” 的相关表述时，不能简单地进行字面翻译，而需要根据目标语言文化背景进行适当调整。又如，英文中的 “a piece of cake” 直译为 “一块蛋糕”，但实际含义是 “小菜一碟”，在汉译时需要准确传达其比喻义。为应对文化差异挑战，翻译模型需要学习不同文化背景下的语言表达习惯和文化内涵，这通常需要结合大规模跨文化语料库以及知识图谱等外部资源，使模型能够理解并正确转换具有文化特色的语言表达。

*   **低资源语言翻译**：对于世界上众多使用人数较少的低资源语言，由于其可用的语料库规模有限，传统的基于大量数据训练的翻译模型往往难以取得理想效果。为解决这一问题，研究人员通常采用迁移学习的方法。即先在高资源语言（如英语、中文、西班牙语等）的大规模语料上进行预训练，学习到通用的语言知识和语义表示，然后利用少量低资源语言的语料对模型进行微调，将高资源语言学习到的知识迁移到低资源语言翻译任务中。此外，还可以通过构建多语言联合训练模型，利用高资源语言与低资源语言之间的相似性，在训练过程中让模型相互学习，提升低资源语言翻译质量。

*   **评估指标**：
    *   **BLEU（Bilingual Evaluation Understudy）**：BLEU 是机器翻译领域应用最为广泛的评估指标之一。它通过计算生成的译文与人工参考译文之间的 n - gram 重叠度来衡量翻译质量。具体来说，它会统计生成译文中出现的 1 - gram（单个单词）、2 - gram（相邻两个单词组成的词组）、3 - gram（相邻三个单词组成的词组）等在参考译文中出现的比例，并结合一定的权重计算综合得分。BLEU 得分越高，表明生成译文与参考译文越相似，翻译质量相对越高。然而，BLEU 指标存在一定局限性，它仅仅关注了单词和词组的表面匹配，忽略了语义的合理性和句子结构的准确性。例如，一个翻译结果可能通过堆砌与参考译文相同的单词和词组获得较高的 BLEU 分数，但句子整体语义可能并不通顺或准确。

    *   **CHRF**：CHRF（Character - n - gram F - score）指标则侧重于字符级别的匹配，更适合处理一些短文本或形态丰富的语言（如德语、俄语等）的翻译评估。它通过计算生成译文和参考译文在字符 n - gram 层面的重叠情况来评估翻译质量，能够在一定程度上弥补 BLEU 指标在处理形态变化丰富语言时的不足。例如，在德语中，名词有性、数、格的变化，动词有变位形式，CHRF 能够更好地捕捉这些基于字符层面的语言变化信息，对翻译结果进行更全面的评估。但 CHRF 同样也不能完全反映译文的语义准确性和流畅性等高级语义特征。

## 二、问答任务（Question Answering, QA）

### 1. 任务定义

问答任务旨在根据输入的自然语言问题以及给定的上下文信息（在某些开放域问答场景中，可能需要从海量知识库或互联网中检索相关上下文），生成准确、简洁的答案。例如，对于问题 “《红楼梦》的作者是谁？”，若给定包含《红楼梦》相关介绍的上下文，模型应能从其中抽取或推理出答案 “曹雪芹”。问答系统的目标是模拟人类回答问题的能力，为用户提供有价值的信息检索和解答服务，广泛应用于智能客服、知识问答平台、智能助手等场景。

### 2. 任务分类



*   **按答案来源**：

*   **封闭域 QA**：封闭域问答的答案严格限定在给定的上下文范围内。典型的封闭域问答任务如阅读理解型问答，常见的数据集如 SQuAD（Stanford Question Answering Dataset）。在这类任务中，模型会先读取一段文本（如一篇新闻报道、一段学术论文节选等）作为上下文，然后针对基于该文本提出的问题进行回答。例如，给定一篇关于某科学实验的文章，问题可能是 “该实验的主要结论是什么？”，模型需要从文章中提取出与问题相关的关键信息，组织成答案。封闭域 QA 的优势在于答案范围明确，模型可以集中精力在有限的文本内进行信息检索和推理，相对更容易实现较高的准确率。但它对上下文的依赖性较强，若上下文提供的信息不完整或不准确，可能导致答案错误。
*   **开放域 QA**：开放域问答的答案来源更为广泛，需要从海量的知识库（如维基百科、百度百科等结构化知识图谱）或互联网中检索相关信息来回答问题。例如，当用户提问 “地球半径是多少？”，模型需要从大量的知识源中找到关于地球半径的准确信息，并以合适的形式组织成答案返回给用户。开放域 QA 的挑战在于如何高效地从海量信息中筛选出与问题相关的内容，并进行准确的推理和回答。为了解决这一问题，通常需要结合信息检索技术（如基于关键词匹配的搜索引擎技术、基于语义理解的检索模型等）和自然语言处理技术（如文本分类、实体识别、关系抽取等），先从知识库或互联网中检索出可能与问题相关的文档或知识片段，再利用问答模型对这些信息进行处理，提取出最终答案。
*   **按答案形式**：

*   **抽取式 QA**：抽取式问答的答案是直接从给定上下文中抽取的连续子片段。例如，给定文本 “苹果公司在 2023 年发布了新款 iPhone，该手机具有强大的拍照功能。”，对于问题 “苹果公司在何时发布了新款 iPhone？”，抽取式问答模型应能从文本中准确抽取 “2023 年” 作为答案。这类任务的核心在于准确识别答案在上下文中的起始和结束位置，通常使用基于深度学习的模型，如 BERT（Bidirectional Encoder Representations from Transformers）及其变体。模型通过对输入的 “\[CLS] 问题 \[SEP] 上下文 \[SEP]” 格式文本进行编码，预测每个位置作为答案起始和结束的概率，从而确定答案片段。抽取式 QA 适用于答案明确存在于给定文本中的情况，具有较高的准确性和可解释性，但对于需要对上下文信息进行综合推理或重新组织语言才能得到答案的问题，则显得力不从心。

*   **生成式 QA**：生成式问答需要模型根据问题和上下文信息，重新组织语言生成答案，而不仅仅是抽取原文片段。例如，对于问题 “为什么天空是蓝色的？”，模型需要理解光的散射原理等相关知识，并以自然语言的形式生成一段解释性的文字作为答案，如 “天空呈现蓝色是因为太阳光中的蓝光波长较短，在穿过大气层时更容易被空气分子散射，从而使得天空看起来是蓝色的。” 生成式 QA 能够处理更复杂、需要推理和知识整合的问题，但对模型的语言生成能力和知识储备要求较高。目前，生成式 QA 通常基于预训练的语言生成模型，如 GPT（Generative Pretrained Transformer）系列，通过在大规模语料上进行训练，学习语言生成的模式和知识，然后针对具体问题进行微调或直接生成答案。

*   **多轮 QA**：多轮问答任务基于多轮对话历史进行回答，模拟人类真实对话场景。在多轮对话中，后续问题往往与之前的问题和回答存在语义关联。例如，第一轮对话中用户提问 “推荐一部科幻电影？”，系统回答 “《星际穿越》”；第二轮用户接着问 “导演是谁？”，此时系统需要结合第一轮的对话历史，理解 “导演” 指的是《星际穿越》的导演，并回答 “克里斯托弗・诺兰”。多轮 QA 需要模型具备良好的上下文理解和记忆能力，能够跟踪对话主题的变化，准确理解用户意图。实现多轮 QA 通常需要结合对话管理技术，维护对话状态，记录用户的问题和系统的回答，同时利用自然语言理解和生成技术对每一轮的输入进行处理和回复。

### 3. 核心技术与模型



*   **抽取式 QA**：

*   **典型模型**：BERT 模型在抽取式 QA 任务中表现卓越。BERT 是一种基于 Transformer 架构的预训练语言模型，通过在大规模无监督语料上进行双向语言模型预训练，学习到了丰富的语言语义和句法知识。在抽取式 QA 任务中，将问题和上下文拼接成 “\[CLS] 问题 \[SEP] 上下文 \[SEP]” 的格式输入 BERT 模型，模型会对每个位置的词进行编码，得到其上下文相关的表示。然后，通过在 BERT 模型之上添加一层线性分类器，预测每个位置作为答案起始和结束位置的概率。例如，对于问题 “文章中提到的新技术的优势是什么？”，BERT 模型会对输入文本进行处理，输出每个词位置作为答案起始和结束的概率分布，取概率最高的区间作为最终答案。为了进一步提升性能，还可以采用一些改进策略，如多模型融合、引入外部知识增强等。

*   **流程**：以 BERT 模型为例，输入文本经过词嵌入（将单词转化为向量表示）、位置嵌入（编码单词在句子中的位置信息）和段嵌入（区分问题和上下文）后，进入多层 Transformer 编码器进行特征提取。在编码器中，自注意力机制使得模型能够捕捉到文本中不同位置单词之间的语义关系。经过编码器处理后，得到每个位置的上下文表示。接着，将这些表示分别输入到两个独立的线性分类层，一个用于预测答案起始位置，另一个用于预测答案结束位置。通过计算每个位置的预测概率，最终确定答案在上下文中的区间。在训练过程中，使用标注好答案的数据集，通过最小化预测结果与真实答案位置之间的损失函数（如交叉熵损失）来调整模型参数，使模型逐渐学习到准确抽取答案的能力。

*   **开放域 QA**：

* **核心框架**：开放域 QA 的核心框架通常是 “检索 + 阅读理解”。首先，利用信息检索技术从海量知识库或互联网中检索出与问题相关的文档或知识片段。常用的检索方法包括基于关键词匹配的 BM25 算法，它根据问题中的关键词在文档中的出现频率、位置等信息对文档进行排序，返回与问题相关性较高的文档。近年来，基于深度学习的密集检索模型，如 DPR（Dense Passage Retrieval）也得到了广泛应用。DPR 通过将问题和文档分别编码为向量，利用向量相似度来衡量问题与文档的相关性，能够更准确地筛选出相关文档。在检索到相关文档后，再利用类似于封闭域 QA 中的阅读理解模型（如 BERT 等）对文档进行处理，从文档中提取出问题的答案。例如，对于问题 “世界上最高的山峰是哪座？”，先通过检索模型从维基百科等知识库中找到关于山峰介绍的相关文档，然后使用阅读理解模型从这些文档中提取出 “珠穆朗玛峰” 作为答案。

*   **挑战**：

*   **常识推理**：许多问题的回答需要依赖隐含的常识知识，这对问答模型来说是一大挑战。例如，问题 “为什么夏天白天比冬天长？”，要准确回答这个问题，模型需要知道地球公转的相关常识，即地球公转轨道是椭圆形，并且地轴存在倾斜，导致在不同季节太阳直射点位置不同，从而造成昼夜长短变化。然而，现有的问答模型往往难以从给定的文本中直接获取这类常识知识，需要引入外部常识知识库（如 ConceptNet 等），或者通过在大规模包含常识信息的语料上进行预训练，让模型学习到这些隐含的常识知识，从而具备基于常识进行推理回答问题的能力。

*   **歧义问题**：自然语言中存在大量歧义问题，这给问答系统带来了困难。例如，问题 “他是谁？”，在没有上下文的情况下，“他” 指代的对象不明确，模型无法准确回答。即使在有上下文的情况下，也可能存在指代模糊的情况。为了解决歧义问题，模型需要具备强大的上下文理解和语义推理能力，能够通过分析上下文信息、人物关系、事件逻辑等，准确判断代词或模糊表述所指代的具体对象。通常可以利用语义角色标注、共指消解等技术，先对文本中的代词和名词短语进行分析，确定其指代关系，再结合问题进行回答。同时，引入对话历史信息和多轮交互机制，也有助于澄清歧义，让用户进一步明确问题意图。

